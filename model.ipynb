{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5303622-6ac0-4834-a6ce-dd430d9948b9",
   "metadata": {},
   "source": [
    "# DECISION TREE\n",
    "\n",
    "Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cc37217-475c-453c-b3ad-6dc950ade9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888b037-189c-4225-a3c9-4591e448e0e9",
   "metadata": {},
   "source": [
    "## STEP 1: Plan \n",
    " - Let's Examine the Titanic DataSet\n",
    " - Can we accurately predict the survival of passengers on the Titanic based on categorical data, such as age, gender, passenger class, or fare.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e60840-95cf-4577-ac1d-04d3b492fb65",
   "metadata": {},
   "source": [
    "## STEP 2: Acquire\n",
    " - Acquire the data we have cleaned and prepped using our previous funtions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d76e0de-5175-49bb-aa52-117cd071aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from csv file...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9402a-0fe3-4cd3-9c78-57482ea14edb",
   "metadata": {},
   "source": [
    "## STEP 3: Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "606927a6-7cc5-4270-8005-feefc07fd849",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cade764d-99e9-477a-8894-14b40e3ce9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex  sibsp  parch     fare  embark_town  alone  \\\n",
       "0         0       3    male      1      0   7.2500  Southampton      0   \n",
       "1         1       1  female      1      0  71.2833    Cherbourg      0   \n",
       "2         1       3  female      0      0   7.9250  Southampton      1   \n",
       "3         1       1  female      1      0  53.1000  Southampton      0   \n",
       "4         0       3    male      0      0   8.0500  Southampton      1   \n",
       "\n",
       "   sex_male  embark_town_Queenstown  embark_town_Southampton  \n",
       "0         1                       0                        1  \n",
       "1         0                       0                        0  \n",
       "2         0                       0                        1  \n",
       "3         0                       0                        1  \n",
       "4         1                       0                        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191ac554-ec4c-4d30-b590-65901b6625a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass  sibsp  parch     fare  alone  sex_male  \\\n",
       "0         0       3      1      0   7.2500      0         1   \n",
       "1         1       1      1      0  71.2833      0         0   \n",
       "2         1       3      0      0   7.9250      1         0   \n",
       "3         1       1      1      0  53.1000      0         0   \n",
       "4         0       3      0      0   8.0500      1         1   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  \n",
       "0                       0                        1  \n",
       "1                       0                        0  \n",
       "2                       0                        1  \n",
       "3                       0                        1  \n",
       "4                       0                        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afe35aa-cf0c-4199-8b28-a4a2a5512809",
   "metadata": {},
   "source": [
    "Prepare - Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0fe43b-307a-4b85-9405-957a6fd74295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db637097-0a5e-465c-a402-e30f5e5dfc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, target, seed=123):\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    print(f'train --> {train.shape}')\n",
    "    print(f'validate --> {validate.shape}')\n",
    "    print(f'test --> {test.shape}')\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df1fb2f-a3cf-45e1-9c3e-66f7cf7d2092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train --> (498, 9)\n",
      "validate --> (214, 9)\n",
      "test --> (179, 9)\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = train_validate_test_split(df, 'survived', seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26ca26f-3fa4-4dd0-abbe-6836ff4d865d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b92982d6-455b-45eb-ace4-a2964f34f584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6772d56e-ef11-4f77-a2ef-ee1d7df0ce41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b7dedb-b207-4764-9381-f078e4a8e25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train --> (498, 9)\n",
      "validate --> (214, 9)\n",
      "test --> (179, 9)\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = train_validate_test_split(df, target='survived', seed=123)\n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17f2d841-e24a-47f4-a737-8915c5d38a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  sibsp  parch      fare  alone  sex_male  embark_town_Queenstown  \\\n",
       "583       1      0      0   40.1250      1         1                       0   \n",
       "165       3      0      2   20.5250      0         1                       0   \n",
       "50        3      4      1   39.6875      0         1                       0   \n",
       "259       2      0      1   26.0000      0         0                       0   \n",
       "306       1      0      0  110.8833      1         0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "583                        0  \n",
       "165                        1  \n",
       "50                         1  \n",
       "259                        1  \n",
       "306                        0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77821900-2a20-484a-a788-9f14dd40b0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beb12e00-94bd-4d9f-b0b8-ed49358cfbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cc6dcb5-6adf-4cdc-b72c-b790819503ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "546ecb1d-3e23-4e8b-a322-0e7e5cad31ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e85a3c-c8e8-44d7-98de-d50af74dc386",
   "metadata": {},
   "source": [
    "## STEP 4: EXPLORATION / PRE-PROCESSING\n",
    "- Done previously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94911f9c-8562-4e14-92fb-23caad46787b",
   "metadata": {},
   "source": [
    "## STEP 5: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef01f5a-a91b-4a64-a7f4-c57871876fa2",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "1.  a. What is your baseline prediction? \n",
    "\n",
    "    b. What is your baseline accuracy? \n",
    "    - remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d542ad15-8b36-4453-964b-a526ff22202e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583    0\n",
       "165    1\n",
       "50     0\n",
       "259    1\n",
       "306    1\n",
       "308    0\n",
       "314    0\n",
       "883    0\n",
       "459    0\n",
       "180    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2303976f-6eef-43c4-8ccd-924b60c5914d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain our mode (most occuring outcome)\n",
    "train.survived.value_counts()\n",
    "\n",
    "# baseline assumption = Did NOT survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01e0dc3c-9ed5-4378-9355-5efa79e06deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Obtain the mode for the target\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# produce boolean array with True assigned to match the baseline prediction and real data. \n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "\n",
    "print(f'Baseline Accuracy: {round(baseline_accuracy, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a0647-c314-4aef-ab6a-78467c7159f3",
   "metadata": {},
   "source": [
    "### Fit - Transform\n",
    "2. Fit the decision tree classifier to your training sample and transform \n",
    "- (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7259b32b-3510-4f8a-aa3d-926605939954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "clf1 = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "#Fit the model (on train and only train)\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train first\n",
    "\n",
    "y_predictions = clf1.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3ddf0cb-66a5-4171-b7e2-b7211908ae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- sex_male <= 0.50\n",
      "|   |--- class: 1\n",
      "|--- sex_male >  0.50\n",
      "|   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(export_text(clf1, feature_names=X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bcf36-8656-43e0-ae55-498a57a525a1",
   "metadata": {},
   "source": [
    "### Evaluate Performance\n",
    "\n",
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80bf12c8-cb89-44b5-aac8-de5486c21cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier on trianing set: 0.80\n"
     ]
    }
   ],
   "source": [
    "tree_score = clf1.score(X_train, y_train)\n",
    "print(f'Accuracy of Decision Tree Classifier on trianing set: {tree_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b8529f1-17bc-492e-9718-c9e0fcc6dea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  265   42\n",
       "1   58  133"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8608fe8-2d8b-4db1-98ea-f6d329fc22a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.82      0.86      0.84       307\\n           1       0.76      0.70      0.73       191\\n\\n    accuracy                           0.80       498\\n   macro avg       0.79      0.78      0.78       498\\nweighted avg       0.80      0.80      0.80       498\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a string object\n",
    "classification_report(y_train, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79689014-5de2-4c23-af99-521a4c8c4b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.820433</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.696335</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.799197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.790217</td>\n",
       "      <td>0.779764</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.797255</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.797358</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.820433  0.863192  0.841270  307.000000\n",
       "1              0.760000  0.696335  0.726776  191.000000\n",
       "accuracy       0.799197  0.799197  0.799197    0.799197\n",
       "macro avg      0.790217  0.779764  0.784023  498.000000\n",
       "weighted avg   0.797255  0.799197  0.797358  498.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a dataframe based off a dictionary\n",
    "\n",
    "classification = classification_report(y_train, y_predictions, output_dict=True)\n",
    "pd.DataFrame(classification).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853968fd-f705-446c-acdb-be8935663e78",
   "metadata": {},
   "source": [
    "### Additional - Calculate Metrics by Hand\n",
    "\n",
    "4. Compute: \n",
    "    - Accuracy, \n",
    "    - true positive rate, \n",
    "    - false positive rate, \n",
    "    - true negative rate, \n",
    "    - false negative rate, \n",
    "    - precision, \n",
    "    - recall, \n",
    "    - f1-score, and \n",
    "    - support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4e7b73f-f959-4b82-b319-49e68f3734b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "True Positive Rate: 0.87\n",
      "False Positive Rate: 0.30\n",
      "True Negative Rate: 0.70\n",
      "False Negative Rate: 0.13\n",
      "Precision: 0.83\n",
      "Recall: 0.87\n",
      "F1: 0.85\n",
      "F1: 318.00\n",
      "F1: 191.00\n"
     ]
    }
   ],
   "source": [
    "# Positives - Did NOT survive\n",
    "\n",
    "TP = 276 \n",
    "FP = 58\n",
    "FN = 42\n",
    "TN = 133\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN) / ALL\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "      \n",
    "true_positive_rate = TP / (TP + FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate:.2f}\")\n",
    "      \n",
    "false_positive_rate = FP /(FP + TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate:.2f}\")\n",
    "      \n",
    "true_negative_rate = TN / (TN + FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate:.2f}\")\n",
    "      \n",
    "false_negative_rate = FN / (FN + TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate:.2f}\")\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "            \n",
    "recall = TP / ( TP + FN)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "f1_score = 2 *(precision*recall) / (precision+recall)\n",
    "print(f\"F1: {f1_score:.2f}\")\n",
    "       \n",
    "support_pos = TP + FN\n",
    "print(f\"F1: {support_pos:.2f}\")\n",
    "      \n",
    "support_neg = FP + TN\n",
    "print(f\"F1: {support_neg:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c277253-60fa-4e13-9411-f65aa7674ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.820433</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.696335</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.799197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.790217</td>\n",
       "      <td>0.779764</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.797255</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.797358</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.820433  0.863192  0.841270  307.000000\n",
       "1              0.760000  0.696335  0.726776  191.000000\n",
       "accuracy       0.799197  0.799197  0.799197    0.799197\n",
       "macro avg      0.790217  0.779764  0.784023  498.000000\n",
       "weighted avg   0.797255  0.799197  0.797358  498.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification = classification_report(y_train, y_predictions, output_dict=True)\n",
    "pd.DataFrame(classification).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bcd92-683c-417d-9c27-9c86fc8404c9",
   "metadata": {},
   "source": [
    "5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc93d2dd-244f-42da-a60f-47a7cd069196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with a max depth of 2\n",
      "              precision    recall  f1-score     support\n",
      "0              0.820433  0.863192  0.841270  307.000000\n",
      "1              0.760000  0.696335  0.726776  191.000000\n",
      "accuracy       0.799197  0.799197  0.799197    0.799197\n",
      "macro avg      0.790217  0.779764  0.784023  498.000000\n",
      "weighted avg   0.797255  0.799197  0.797358  498.000000\n",
      "___________________\n",
      "Tree with a max depth of 3\n",
      "              precision    recall  f1-score     support\n",
      "0              0.828829  0.899023  0.862500  307.000000\n",
      "1              0.812121  0.701571  0.752809  191.000000\n",
      "accuracy       0.823293  0.823293  0.823293    0.823293\n",
      "macro avg      0.820475  0.800297  0.807654  498.000000\n",
      "weighted avg   0.822421  0.823293  0.820430  498.000000\n",
      "___________________\n",
      "Tree with a max depth of 4\n",
      "              precision    recall  f1-score     support\n",
      "0              0.829341  0.902280  0.864275  307.000000\n",
      "1              0.817073  0.701571  0.754930  191.000000\n",
      "accuracy       0.825301  0.825301  0.825301    0.825301\n",
      "macro avg      0.823207  0.801925  0.809602  498.000000\n",
      "weighted avg   0.824636  0.825301  0.822337  498.000000\n",
      "___________________\n",
      "Tree with a max depth of 5\n",
      "              precision    recall  f1-score     support\n",
      "0              0.797368  0.986971  0.882096  307.000000\n",
      "1              0.966102  0.596859  0.737864  191.000000\n",
      "accuracy       0.837349  0.837349  0.837349    0.837349\n",
      "macro avg      0.881735  0.791915  0.809980  498.000000\n",
      "weighted avg   0.862083  0.837349  0.826778  498.000000\n",
      "___________________\n",
      "Tree with a max depth of 6\n",
      "              precision    recall  f1-score     support\n",
      "0              0.830084  0.970684  0.894895  307.000000\n",
      "1              0.935252  0.680628  0.787879  191.000000\n",
      "accuracy       0.859438  0.859438  0.859438    0.859438\n",
      "macro avg      0.882668  0.825656  0.841387  498.000000\n",
      "weighted avg   0.870419  0.859438  0.853851  498.000000\n",
      "___________________\n",
      "Tree with a max depth of 7\n",
      "              precision    recall  f1-score     support\n",
      "0              0.831025  0.977199  0.898204  307.000000\n",
      "1              0.948905  0.680628  0.792683  191.000000\n",
      "accuracy       0.863454  0.863454  0.863454    0.863454\n",
      "macro avg      0.889965  0.828913  0.845443  498.000000\n",
      "weighted avg   0.876236  0.863454  0.857733  498.000000\n",
      "___________________\n",
      "Tree with a max depth of 8\n",
      "              precision    recall  f1-score    support\n",
      "0              0.872093  0.977199  0.921659  307.00000\n",
      "1              0.954545  0.769634  0.852174  191.00000\n",
      "accuracy       0.897590  0.897590  0.897590    0.89759\n",
      "macro avg      0.913319  0.873416  0.886916  498.00000\n",
      "weighted avg   0.903716  0.897590  0.895009  498.00000\n",
      "___________________\n",
      "Tree with a max depth of 9\n",
      "              precision    recall  f1-score     support\n",
      "0              0.892216  0.970684  0.929797  307.000000\n",
      "1              0.945122  0.811518  0.873239  191.000000\n",
      "accuracy       0.909639  0.909639  0.909639    0.909639\n",
      "macro avg      0.918669  0.891101  0.901518  498.000000\n",
      "weighted avg   0.912507  0.909639  0.908105  498.000000\n",
      "___________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,10):\n",
    "\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    y_predictions = tree.predict(X_train)\n",
    "    \n",
    "    classification = classification_report(y_train, y_predictions, output_dict=True)\n",
    "\n",
    "    print(f'Tree with a max depth of {i}')\n",
    "    print(pd.DataFrame(classification).transpose())\n",
    "    print(\"___________________\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77d3a2-0790-48f0-a252-ca24e5cfaad1",
   "metadata": {},
   "source": [
    "6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4c0b0-efca-457f-8f10-f932c1db7b13",
   "metadata": {},
   "source": [
    "The model with a max depth of 9 performs best with an accuracy of 91%. As the depth increases, the accuracy increases, which aslo demonstrates how models can be overfit to the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c91e32d-10ca-4426-b80b-9a5f949ba45e",
   "metadata": {},
   "source": [
    "### Validation\n",
    "7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59419e55-19fa-4903-81bd-60a341c63840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.040254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.080340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.093083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.863454</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.101772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.897590</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.140581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.909639</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.147956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.157340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.931727</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.170045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.941767</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.194104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.186766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.186766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.198120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.198120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.198120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.198120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.198120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           2        0.799197           0.761682    0.037515\n",
       "1           3        0.823293           0.785047    0.038246\n",
       "2           4        0.825301           0.785047    0.040254\n",
       "3           5        0.837349           0.757009    0.080340\n",
       "4           6        0.859438           0.766355    0.093083\n",
       "5           7        0.863454           0.761682    0.101772\n",
       "6           8        0.897590           0.757009    0.140581\n",
       "7           9        0.909639           0.761682    0.147956\n",
       "8          10        0.923695           0.766355    0.157340\n",
       "9          11        0.931727           0.761682    0.170045\n",
       "10         12        0.941767           0.747664    0.194104\n",
       "11         13        0.943775           0.757009    0.186766\n",
       "12         14        0.943775           0.757009    0.186766\n",
       "13         15        0.945783           0.747664    0.198120\n",
       "14         16        0.945783           0.747664    0.198120\n",
       "15         17        0.945783           0.747664    0.198120\n",
       "16         18        0.945783           0.747664    0.198120\n",
       "17         19        0.945783           0.747664    0.198120"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range (2, 20):\n",
    "        # Make the model\n",
    "        tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "        \n",
    "        #Fit the model on TRAIN only)\n",
    "        tree = tree.fit(X_train, y_train)\n",
    "        \n",
    "        #Use the model - on train first, then on validate\n",
    "        in_sample_accuracy = tree.score(X_train, y_train)\n",
    "        \n",
    "        out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "        \n",
    "        output = {\n",
    "            \"max_depth\": i,\n",
    "            \"train_accuracy\": in_sample_accuracy,\n",
    "            \"validate_accuracy\": out_of_sample_accuracy\n",
    "        }\n",
    "        \n",
    "        metrics.append(output)\n",
    "        \n",
    "df = pd.DataFrame(metrics)\n",
    "df['difference'] = df.train_accuracy - df.validate_accuracy\n",
    "\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11e55cbb-38c4-484c-8988-db97c56e144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.080340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.093083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.040254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_accuracy  validate_accuracy  difference\n",
       "3          5        0.837349           0.757009    0.080340\n",
       "0          2        0.799197           0.761682    0.037515\n",
       "4          6        0.859438           0.766355    0.093083\n",
       "1          3        0.823293           0.785047    0.038246\n",
       "2          4        0.825301           0.785047    0.040254"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa13a547-f70b-49ee-81d7-256cd700d881",
   "metadata": {},
   "source": [
    "# RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7780d826-420e-4eaa-8f7e-af5d1a695ece",
   "metadata": {},
   "source": [
    "### Fit - Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7491a-2c2d-4459-b56b-3fdc99083000",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc8e8ed7-719b-460e-83f7-e756406b8315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 10 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.931889</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.948801</td>\n",
       "      <td>0.944862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.980456</td>\n",
       "      <td>0.884817</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.932636</td>\n",
       "      <td>0.943775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.923497</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.939526</td>\n",
       "      <td>0.943260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.931889    0.965714  0.943775    0.948801      0.944862\n",
       "recall       0.980456    0.884817  0.943775    0.932636      0.943775\n",
       "f1-score     0.955556    0.923497  0.943775    0.939526      0.943260\n",
       "support    307.000000  191.000000  0.943775  498.000000    498.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the model\n",
    "forest1 = RandomForestClassifier(min_samples_leaf=1, max_depth=10, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "forest1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = forest1.predict(X_train)\n",
    "\n",
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 10 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724c389-a6a0-454d-a72f-87001bf0815c",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bfd7bb-dec3-47d8-834f-fa87376aa450",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0edf0f0-3290-446f-8188-99caa02dad43",
   "metadata": {},
   "source": [
    "- See Below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76262384-a928-4e3a-b77d-08abb8c6e4ca",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c91b336a-692f-4aa4-8d7a-5a147db80be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  301   22\n",
       "1    6  169"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "014208b7-598d-4d98-bad4-57abf9720f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The accuracy for our model is 0.9438\n",
      "    The True Positive Rate is 0.885, The False Positive Rate is 0.0195,\n",
      "    The True Negative Rate is 0.98, and the False Negative Rate is 0.115\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.931889</td>\n",
       "      <td>0.965714</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.948801</td>\n",
       "      <td>0.944862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.980456</td>\n",
       "      <td>0.884817</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.932636</td>\n",
       "      <td>0.943775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.923497</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.939526</td>\n",
       "      <td>0.943260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.931889    0.965714  0.943775    0.948801      0.944862\n",
       "recall       0.980456    0.884817  0.943775    0.932636      0.943775\n",
       "f1-score     0.955556    0.923497  0.943775    0.939526      0.943260\n",
       "support    307.000000  191.000000  0.943775  498.000000    498.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = forest1.predict(X_train)\n",
    "forest_score = forest1.score(X_train, y_train)\n",
    "conf = confusion_matrix(y_train, y_pred1)\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print(f'''\n",
    "    The accuracy for our model is {forest_score:.4}\n",
    "    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n",
    "    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n",
    "    ''')\n",
    "pd.DataFrame(classification_report(y_train, y_pred1, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7f274-0fdb-4e11-9571-18da8dbd9aad",
   "metadata": {},
   "source": [
    "### Review Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c851692-4d9e-488e-ad2b-639734c312b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positives - Did NOT survive\n",
    "TP = 169 \n",
    "FP = 58\n",
    "FN = 42\n",
    "TN = 301\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN) / ALL\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "      \n",
    "true_positive_rate = TP / (TP + FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate:.2f}\")\n",
    "      \n",
    "false_positive_rate = FP /(FP + TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate:.2f}\")\n",
    "      \n",
    "true_negative_rate = TN / (TN + FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate:.2f}\")\n",
    "      \n",
    "false_negative_rate = FN / (FN + TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate:.2f}\")\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "            \n",
    "recall = TP / ( TP + FN)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "f1_score = 2 *(precision*recall) / (precision+recall)\n",
    "print(f\"F1: {f1_score:.2f}\")\n",
    "       \n",
    "support_pos = TP + FN\n",
    "print(f\"F1: {support_pos:.2f}\")\n",
    "      \n",
    "support_neg = FP + TN\n",
    "print(f\"F1: {support_neg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830e7cae-536a-43eb-a2e0-6327079b47d3",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e021a825-f95a-4a60-a1cf-cf19454cd1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.774799    0.856000  0.795181    0.815399      0.805942\n",
      "recall       0.941368    0.560209  0.795181    0.750789      0.795181\n",
      "f1-score     0.850000    0.677215  0.795181    0.763608      0.783731\n",
      "support    307.000000  191.000000  0.795181  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.813754    0.845638  0.823293    0.829696      0.825982\n",
      "recall       0.925081    0.659686  0.823293    0.792384      0.823293\n",
      "f1-score     0.865854    0.741176  0.823293    0.803515      0.818036\n",
      "support    307.000000  191.000000  0.823293  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.816384    0.875000  0.833333    0.845692      0.838865\n",
      "recall       0.941368    0.659686  0.833333    0.800527      0.833333\n",
      "f1-score     0.874433    0.752239  0.833333    0.813336      0.827567\n",
      "support    307.000000  191.000000  0.833333  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.828571    0.885135  0.845382    0.856853      0.850266\n",
      "recall       0.944625    0.685864  0.845382    0.815245      0.845382\n",
      "f1-score     0.882801    0.772861  0.845382    0.827831      0.840635\n",
      "support    307.000000  191.000000  0.845382  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.878338    0.931677  0.895582    0.905008      0.898796\n",
      "recall       0.964169    0.785340  0.895582    0.874755      0.895582\n",
      "f1-score     0.919255    0.852273  0.895582    0.885764      0.893565\n",
      "support    307.000000  191.000000  0.895582  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.887240    0.950311  0.907631    0.918775      0.911430\n",
      "recall       0.973941    0.801047  0.907631    0.887494      0.907631\n",
      "f1-score     0.928571    0.869318  0.907631    0.898945      0.905846\n",
      "support    307.000000  191.000000  0.907631  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.903614    0.957831  0.921687    0.930723      0.924408\n",
      "recall       0.977199    0.832461  0.921687    0.904830      0.921687\n",
      "f1-score     0.938967    0.890756  0.921687    0.914862      0.920477\n",
      "support    307.000000  191.000000  0.921687  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.929012    0.965517  0.941767    0.947265      0.943013\n",
      "recall       0.980456    0.879581  0.941767    0.930019      0.941767\n",
      "f1-score     0.954041    0.920548  0.941767    0.937295      0.941195\n",
      "support    307.000000  191.000000  0.941767  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.931889    0.965714  0.943775    0.948801      0.944862\n",
      "recall       0.980456    0.884817  0.943775    0.932636      0.943775\n",
      "f1-score     0.955556    0.923497  0.943775    0.939526      0.943260\n",
      "support    307.000000  191.000000  0.943775  498.000000    498.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#From Lesson Review Example\n",
    "for i in range(2, 11):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = forest.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5b3b9-039f-41bb-a796-a19c6836711d",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac5995-0234-4788-873b-130a4c241453",
   "metadata": {},
   "source": [
    "- The test that produces the best metrics is the max depth of 10 at 94.3% accuracy, 32% better than baseline. This is because it is better fit to the training data, havinvg more depth. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00857b1-3293-4586-96d8-f941cf0b5bce",
   "metadata": {},
   "source": [
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0677f2d5-3088-42ca-a8c9-75c18a168e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.024153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.047592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.038941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.036970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.895582</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.087171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.907631</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.113238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.117948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.941767</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.152047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.158728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.165409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           2        0.795181           0.771028    0.024153\n",
       "1           3        0.823293           0.775701    0.047592\n",
       "2           4        0.833333           0.794393    0.038941\n",
       "3           5        0.845382           0.808411    0.036970\n",
       "4           6        0.895582           0.808411    0.087171\n",
       "5           7        0.907631           0.794393    0.113238\n",
       "6           8        0.921687           0.803738    0.117948\n",
       "7           9        0.941767           0.789720    0.152047\n",
       "8          10        0.943775           0.785047    0.158728\n",
       "9          11        0.945783           0.780374    0.165409\n",
       "10         12        0.945783           0.780374    0.165409\n",
       "11         13        0.945783           0.780374    0.165409\n",
       "12         14        0.945783           0.780374    0.165409\n",
       "13         15        0.945783           0.780374    0.165409\n",
       "14         16        0.945783           0.780374    0.165409\n",
       "15         17        0.945783           0.780374    0.165409\n",
       "16         18        0.945783           0.780374    0.165409\n",
       "17         19        0.945783           0.780374    0.165409\n",
       "18         20        0.945783           0.780374    0.165409\n",
       "19         21        0.945783           0.780374    0.165409\n",
       "20         22        0.945783           0.780374    0.165409\n",
       "21         23        0.945783           0.780374    0.165409\n",
       "22         24        0.945783           0.780374    0.165409"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from Lesson Review\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e09a046-1e48-4c40-b164-9206d857fe8c",
   "metadata": {},
   "source": [
    "- The model that performed best on out of sample data was the one with a max depth of 6. It had 80.8% accuracy on unseen data, which is 18% better than baseline, while also displaying 90% accuracy on train. It had a small difference between train and validate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f194fc29-f0b8-41fb-a6ed-f5810343f8c6",
   "metadata": {},
   "source": [
    "# K-NEAREST NEIGHBORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae61cd-89d7-4190-a147-d7ab0177cee2",
   "metadata": {},
   "source": [
    "Continue working in your model file with the titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bfc3ff-9026-4c65-a76f-16c6e5facc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10a14a-9421-46ad-8d74-78964d0db449",
   "metadata": {},
   "source": [
    "## STEP 2: Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e65e9-84ea-4a40-89f8-9a4bb01484ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c2bd3-43a3-435e-a201-83ec0c19d659",
   "metadata": {},
   "source": [
    "## STEP 3: Prepare - Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110774d-4628-4d36-99b9-d1a9b557a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.prep_titanic(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f88ca-5d79-4193-8dad-193f409b10d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary data\n",
    "df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e58a85-8727-4335-a121-504244c196de",
   "metadata": {},
   "source": [
    "#### Prepare - Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c1a4c7-bd93-4a2c-a4a3-d16d5b93dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, 'survived', seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc91cba-0bcf-463a-9b27-0bc98e06209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify shape to make sure they are appropriate splits.\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10baddde-7b64-4f8c-b168-234d1f512403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618dc441-8d36-4b0d-8a37-df829cbb8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e1614-738d-45b0-898b-c38ad288c461",
   "metadata": {},
   "source": [
    "## STEP 4: EXPLORATION / PRE-PROCESSING\n",
    "- Done previously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec0bc7d-e29f-4d47-86c8-844abbbd0355",
   "metadata": {},
   "source": [
    "## STEP 5: MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c271156-72a3-4ed9-8eac-8aa076710bce",
   "metadata": {},
   "source": [
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79161d5-14c0-4eec-a0b0-49d4d310c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KNN Object \n",
    "# weights = ['uniform', 'density']\n",
    "knn1 = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45cc9e-618c-414e-a342-2b97b14bd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "knn1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aeeace-718a-4897-b00a-77bd2ef789c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions\n",
    "y_pred = knn1.predict_proba(X_train[['sex','pclass']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a514c-411a-42a8-93c2-5c448509f506",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb95db0-78ed-4575-883e-d5a09bfcdfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c4f0e-a6c9-469c-9606-dc42d499d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f80472-badf-4a3b-ac2d-e83e837feb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_train, y_pred, output_dict=True)\n",
    "print('n_neightbor = 1')\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08881431-b729-4869-8af4-6d0d1a0823be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3e4988-2eb2-4c5b-a7a3-f8cf6492e0eb",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9446c-d21a-4f6c-8e5d-2f2d8aa76f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78696b-c984-43e6-b971-34ee62e0085d",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fbb62-a90b-437f-a96e-56599b1aacd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e0dbbc5-8739-4e72-98e8-94fadd4d6ab0",
   "metadata": {},
   "source": [
    "5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190f11f3-5dac-45ad-b5ba-5a58926c6c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "435c1c62-a46a-4048-a5f4-3fdd63fd2360",
   "metadata": {},
   "source": [
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1827a-e86d-4bac-ab29-1e8823902862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4204471-9bed-493f-8579-1792b4ebac4d",
   "metadata": {},
   "source": [
    "7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbd509-99f8-4021-bb80-55c7878f7165",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627fb18-b3a0-4736-b3ec-678ad150c8ca",
   "metadata": {},
   "source": [
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. \n",
    "- Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. \n",
    "- The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbaeda-7e96-40e7-8383-3c340acfb75d",
   "metadata": {},
   "source": [
    "- For all of the models you create, choose a threshold that optimizes for accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c31c2-3598-4484-aeaf-8cb2bd636f57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 2: Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbe9cf-a930-41f1-a8f8-1f4e02abb8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e7bb8-d0b1-4e16-923e-5d3d77f92397",
   "metadata": {},
   "source": [
    "## STEP 3: Prepare - Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94234527-6547-4af1-b26d-ebdf86bafebf",
   "metadata": {},
   "source": [
    "#### Prepare: Clean Null Values ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3fc02a-5fdf-470c-8ef4-f0b6fd77849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHECK FOR NULL VALUES ### \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c9f2e-c05b-42f7-9887-c02b07c1eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using - age -> 177 null values\n",
    "# What to do with deck?\n",
    "\n",
    "# Use the average age to full in the null values within the age column.\n",
    "avg_age = df.age.mean()\n",
    "df.age = df.age.fillna(avg_age)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db7e4e-8a2c-4c8f-952f-19f1192f986a",
   "metadata": {},
   "source": [
    "#### Prepare: Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec9c576-7ff6-4848-997a-c79ef8537c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode string(categorical) values into numberic values so the computer can read them. \n",
    "\n",
    "df[\"is_female\"] = (df.sex == 'female').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26792e2d-ffee-4d26-b1d5-729e291f9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy vairables to encode embarktown into numberic values\n",
    "dummy_df = pd.get_dummies(df[['embark_town']], dummy_na=False, drop_first=True)\n",
    "\n",
    "#reassign df with added colums for embark_town\n",
    "df = pd.concat([df, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf463dfe-de92-4536-9cb2-8662bf32d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns, like columns we used to encode data\n",
    "\n",
    "df = df.drop(columns=[\"passenger_id\", \"deck\", \"class\", \"embarked\", \"sex\", \"embark_town\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec40cff-df0f-4cec-a420-96d20eedfa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd5b07-4b3a-493e-b0b6-018431e71e41",
   "metadata": {},
   "source": [
    "#### Prepare - Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba100a-764f-4d08-a1e0-1acbb71871c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the datasets\n",
    "train, validate, test = train_validate_test_split(df, 'survived', seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9f5fd-116b-4d4d-a4ee-247eca44379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e149d210-8365-44a7-aa6c-f90a1b347c09",
   "metadata": {},
   "source": [
    "#### Prepare - Assign X and y values for splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3fcf75-4cd5-4c76-a621-94de456a4d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out our X and y values from each dataset\n",
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7d09f-2dd7-4ae1-a66a-9012711e1f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d579a-24e5-4c11-868e-7953f62186d6",
   "metadata": {},
   "source": [
    "## STEP 4: EXPLORATION / PRE-PROCESSING\n",
    "- Done previously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516889f-9360-471d-9b95-3f3a9d75a0b1",
   "metadata": {},
   "source": [
    "## STEP 5: MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a00da2-279b-47a4-8b96-a13fc097f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify mode for X variable\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e02f40-3c72-4c06-8696-8ce1a108f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mode to set baseline\n",
    "\n",
    "# Obtain the mode for the target\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# produce boolean array with True assigned to match the baseline prediction and real data. \n",
    "matches_baseline_prediction = (y_train == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "\n",
    "print(f'Baseline Accuracy: {round(baseline_accuracy, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d54cd7-8073-4071-a073-719bcdb80b4f",
   "metadata": {},
   "source": [
    "### EXERCISE 1\n",
    "1. Create a model that includes age in addition to fare and pclass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff00213-7561-428a-8996-114cc77351ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdae33a5-ff16-426c-aaa5-539bc4c25c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use logistic regression\n",
    "\n",
    "logit = LogisticRegression(random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f0ef3-1895-48fc-9424-6c79acf16aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the features we will use (listed in the problem)\n",
    "\n",
    "features = ['age', 'pclass', 'fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45843e-05d9-4ea2-8f74-82d5acfe5414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using only the features desired.\n",
    "\n",
    "logit.fit(X_train[features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca1790-3b5f-4df5-a73f-9578fb9d0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the same set of features we fit the model to. \n",
    "\n",
    "y_pred = logit.predict(X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c7792-57bc-439c-8999-d96e7cbf1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisit baseline and compare to logistic regression classifier.\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455289d-f513-43cc-b1f6-14f8b414a4e5",
   "metadata": {},
   "source": [
    "- Does this model perform better than your baseline?\n",
    "\n",
    "-- The model performs with an accuracy of .70, which is .08 better than the baseline of .62"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06be96-2122-49a9-b689-d92a88922371",
   "metadata": {},
   "source": [
    "### EXERCISE 2\n",
    "2. Include sex in your model as well. \n",
    "- Note that you'll need to encode or create a dummy variable of this feature before including it in a model (previously completed -> is_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed008ee-8ff7-4115-9c14-5cd3e74e66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use logistic regression\n",
    "logit = LogisticRegression(random_state=123)\n",
    "\n",
    "# Set the features we will use (listed in the problem)\n",
    "features = ['age', 'pclass', 'fare', 'is_female']\n",
    "\n",
    "# Fit the model using only the features desired.\n",
    "logit.fit(X_train[features], y_train)\n",
    "\n",
    "# Predict on the same set of features we fit the model to. \n",
    "y_pred = logit.predict(X_train[features])\n",
    "\n",
    "# Revisit baseline and compare to logisticc regression classifier.\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[features], y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ea9ba-2ff9-4a34-a6ba-2935b0c85d68",
   "metadata": {},
   "source": [
    "- Does this model perform better than your baseline?\n",
    "\n",
    "-- The model performs with an accuracy of .81, which is .19 better than the baseline of .62"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf654c6-0773-4841-abc5-bd7cf47c3887",
   "metadata": {},
   "source": [
    "### EXERCISE 3\n",
    "\n",
    "3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d505f-0434-44f8-9d47-d8af65f70aa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EXERCISE 4\n",
    "\n",
    "4. Use your best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad5a85-d0ed-4248-ba5d-99fcc5d85904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5215e6d-58d7-4666-9716-3cdaf7df5931",
   "metadata": {},
   "source": [
    "### EXERCISE 5\n",
    "\n",
    "5. Choose your best model from the validation performation, and evaluate it on the test dataset. \n",
    "- How do the performance metrics compare to validate? \n",
    "- How do the performance metrics compare to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302b99f-dade-4e91-960c-91c26c0dfd52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
